{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install autogluon==0.8.2\n"
      ],
      "metadata": {
        "id": "1GRS_nKG6JQg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d9f6ce4-fd87-46a5-e884-2464a3718ff7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: autogluon==0.8.2 in /usr/local/lib/python3.10/dist-packages (0.8.2)\n",
            "Requirement already satisfied: autogluon.core[all]==0.8.2 in /usr/local/lib/python3.10/dist-packages (from autogluon==0.8.2) (0.8.2)\n",
            "Requirement already satisfied: autogluon.features==0.8.2 in /usr/local/lib/python3.10/dist-packages (from autogluon==0.8.2) (0.8.2)\n",
            "Requirement already satisfied: autogluon.tabular[all]==0.8.2 in /usr/local/lib/python3.10/dist-packages (from autogluon==0.8.2) (0.8.2)\n",
            "Requirement already satisfied: autogluon.multimodal==0.8.2 in /usr/local/lib/python3.10/dist-packages (from autogluon==0.8.2) (0.8.2)\n",
            "Requirement already satisfied: autogluon.timeseries[all]==0.8.2 in /usr/local/lib/python3.10/dist-packages (from autogluon==0.8.2) (0.8.2)\n",
            "Requirement already satisfied: numpy<1.27,>=1.21 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.8.2->autogluon==0.8.2) (1.23.5)\n",
            "Requirement already satisfied: scipy<1.12,>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.8.2->autogluon==0.8.2) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn<1.3,>=1.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.8.2->autogluon==0.8.2) (1.2.2)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.8.2->autogluon==0.8.2) (3.1)\n",
            "Requirement already satisfied: pandas<1.6,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.8.2->autogluon==0.8.2) (1.5.3)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.8.2->autogluon==0.8.2) (4.65.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.8.2->autogluon==0.8.2) (2.28.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.8.2->autogluon==0.8.2) (3.7.1)\n",
            "Requirement already satisfied: boto3<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.8.2->autogluon==0.8.2) (1.28.62)\n",
            "Requirement already satisfied: autogluon.common==0.8.2 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.8.2->autogluon==0.8.2) (0.8.2)\n",
            "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.8.2->autogluon==0.8.2) (0.2.7)\n",
            "Requirement already satisfied: ray[default]<2.4,>=2.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.8.2->autogluon==0.8.2) (2.3.1)\n",
            "Requirement already satisfied: pydantic<2.0,>=1.10.4 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.8.2->autogluon==0.8.2) (1.10.13)\n",
            "Requirement already satisfied: grpcio<=1.50.0,>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.8.2->autogluon==0.8.2) (1.50.0)\n",
            "Requirement already satisfied: Pillow<9.6,>=9.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->autogluon==0.8.2) (9.4.0)\n",
            "Requirement already satisfied: jsonschema<4.18,>=4.14 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->autogluon==0.8.2) (4.17.3)\n",
            "Requirement already satisfied: seqeval<1.3.0,>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->autogluon==0.8.2) (1.2.2)\n",
            "Requirement already satisfied: evaluate<0.4.0,>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->autogluon==0.8.2) (0.3.0)\n",
            "Requirement already satisfied: accelerate<0.17,>=0.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->autogluon==0.8.2) (0.16.0)\n",
            "Requirement already satisfied: timm<0.10.0,>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->autogluon==0.8.2) (0.9.7)\n",
            "Requirement already satisfied: torch<1.14,>=1.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->autogluon==0.8.2) (1.13.1)\n",
            "Requirement already satisfied: torchvision<0.15.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->autogluon==0.8.2) (0.14.1)\n",
            "Requirement already satisfied: scikit-image<0.20.0,>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->autogluon==0.8.2) (0.19.3)\n",
            "Requirement already satisfied: pytorch-lightning<1.10.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->autogluon==0.8.2) (1.9.5)\n",
            "Requirement already satisfied: text-unidecode<1.4,>=1.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->autogluon==0.8.2) (1.3)\n",
            "Requirement already satisfied: torchmetrics<0.12.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->autogluon==0.8.2) (0.11.4)\n",
            "Requirement already satisfied: transformers[sentencepiece]<4.27.0,>=4.23.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->autogluon==0.8.2) (4.26.1)\n",
            "Requirement already satisfied: nptyping<2.5.0,>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->autogluon==0.8.2) (2.4.1)\n",
            "Requirement already satisfied: omegaconf<2.3.0,>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->autogluon==0.8.2) (2.2.3)\n",
            "Requirement already satisfied: pytorch-metric-learning<2.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->autogluon==0.8.2) (1.7.3)\n",
            "Requirement already satisfied: nlpaug<1.2.0,>=1.1.10 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->autogluon==0.8.2) (1.1.11)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.4.5 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->autogluon==0.8.2) (3.8.1)\n",
            "Requirement already satisfied: openmim<0.4.0,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->autogluon==0.8.2) (0.3.9)\n",
            "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->autogluon==0.8.2) (0.7.1)\n",
            "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->autogluon==0.8.2) (3.1.2)\n",
            "Requirement already satisfied: tensorboard<3,>=2.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->autogluon==0.8.2) (2.13.0)\n",
            "Requirement already satisfied: pytesseract<0.3.11,>=0.3.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->autogluon==0.8.2) (0.3.10)\n",
            "Requirement already satisfied: lightgbm<3.4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (3.3.5)\n",
            "Requirement already satisfied: xgboost<1.8,>=1.6 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (1.7.6)\n",
            "Requirement already satisfied: fastai<2.8,>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (2.7.12)\n",
            "Requirement already satisfied: catboost<1.3,>=1.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (1.2.2)\n",
            "Requirement already satisfied: joblib<2,>=1.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.8.2->autogluon==0.8.2) (1.3.2)\n",
            "Requirement already satisfied: statsmodels<0.15,>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.8.2->autogluon==0.8.2) (0.14.0)\n",
            "Requirement already satisfied: gluonts<0.14,>=0.13.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.8.2->autogluon==0.8.2) (0.13.5)\n",
            "Requirement already satisfied: statsforecast<1.5,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.8.2->autogluon==0.8.2) (1.4.0)\n",
            "Requirement already satisfied: mlforecast<0.7.4,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.8.2->autogluon==0.8.2) (0.7.3)\n",
            "Requirement already satisfied: ujson<6,>=5 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.8.2->autogluon==0.8.2) (5.8.0)\n",
            "Requirement already satisfied: psutil<6,>=5.7.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.common==0.8.2->autogluon.core[all]==0.8.2->autogluon==0.8.2) (5.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from autogluon.common==0.8.2->autogluon.core[all]==0.8.2->autogluon==0.8.2) (60.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<0.17,>=0.9->autogluon.multimodal==0.8.2->autogluon==0.8.2) (23.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate<0.17,>=0.9->autogluon.multimodal==0.8.2->autogluon==0.8.2) (6.0.1)\n",
            "Requirement already satisfied: botocore<1.32.0,>=1.31.62 in /usr/local/lib/python3.10/dist-packages (from boto3<2,>=1.10->autogluon.core[all]==0.8.2->autogluon==0.8.2) (1.31.62)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3<2,>=1.10->autogluon.core[all]==0.8.2->autogluon==0.8.2) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from boto3<2,>=1.10->autogluon.core[all]==0.8.2->autogluon==0.8.2) (0.7.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (0.20.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (1.16.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2->autogluon==0.8.2) (2.14.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2->autogluon==0.8.2) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2->autogluon==0.8.2) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2->autogluon==0.8.2) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2->autogluon==0.8.2) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2->autogluon==0.8.2) (0.18.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2->autogluon==0.8.2) (0.18.0)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (23.1.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.6,>=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (1.5.29)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (1.0.3)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (3.6.1)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.10/dist-packages (from gluonts<0.14,>=0.13.1->autogluon.timeseries[all]==0.8.2->autogluon==0.8.2) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gluonts<0.14,>=0.13.1->autogluon.timeseries[all]==0.8.2->autogluon==0.8.2) (4.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.8.2->autogluon==0.8.2) (0.18.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.8.2->autogluon==0.8.2) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.8.2->autogluon==0.8.2) (0.10.9.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==0.8.2->autogluon==0.8.2) (2.1.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.18,>=4.14->autogluon.multimodal==0.8.2->autogluon==0.8.2) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.18,>=4.14->autogluon.multimodal==0.8.2->autogluon==0.8.2) (0.19.3)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from lightgbm<3.4,>=3.3->autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (0.41.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from mlforecast<0.7.4,>=0.7.0->autogluon.timeseries[all]==0.8.2->autogluon==0.8.2) (0.56.4)\n",
            "Requirement already satisfied: window-ops in /usr/local/lib/python3.10/dist-packages (from mlforecast<0.7.4,>=0.7.0->autogluon.timeseries[all]==0.8.2->autogluon==0.8.2) (0.0.14)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.8.2->autogluon==0.8.2) (4.6.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==0.8.2->autogluon==0.8.2) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==0.8.2->autogluon==0.8.2) (2023.6.3)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==0.8.2->autogluon==0.8.2) (4.9.3)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->autogluon==0.8.2) (0.4.6)\n",
            "Requirement already satisfied: model-index in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->autogluon==0.8.2) (0.1.11)\n",
            "Requirement already satisfied: opendatalab in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->autogluon==0.8.2) (0.0.10)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->autogluon==0.8.2) (13.4.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->autogluon==0.8.2) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<1.6,>=1.4.1->autogluon.core[all]==0.8.2->autogluon==0.8.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<1.6,>=1.4.1->autogluon.core[all]==0.8.2->autogluon==0.8.2) (2023.3.post1)\n",
            "Requirement already satisfied: lightning-utilities>=0.6.0.post0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning<1.10.0,>=1.9.0->autogluon.multimodal==0.8.2->autogluon==0.8.2) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->autogluon==0.8.2) (3.12.4)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->autogluon==0.8.2) (1.0.7)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->autogluon==0.8.2) (3.20.2)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->autogluon==0.8.2) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->autogluon==0.8.2) (1.4.0)\n",
            "Requirement already satisfied: virtualenv>=20.0.24 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->autogluon==0.8.2) (20.24.5)\n",
            "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->autogluon==0.8.2) (3.8.5)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->autogluon==0.8.2) (0.7.0)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->autogluon==0.8.2) (0.5.5)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->autogluon==0.8.2) (0.3.14)\n",
            "Requirement already satisfied: gpustat>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->autogluon==0.8.2) (1.1.1)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->autogluon==0.8.2) (0.11.3)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->autogluon==0.8.2) (0.17.1)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->autogluon==0.8.2) (6.4.0)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->autogluon==0.8.2) (2.6.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==0.8.2->autogluon==0.8.2) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==0.8.2->autogluon==0.8.2) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==0.8.2->autogluon==0.8.2) (1.26.17)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==0.8.2->autogluon==0.8.2) (2023.7.22)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.8.2->autogluon==0.8.2) (2.31.5)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.8.2->autogluon==0.8.2) (2023.9.26)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.8.2->autogluon==0.8.2) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.3,>=1.0->autogluon.core[all]==0.8.2->autogluon==0.8.2) (3.2.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels<0.15,>=0.13.0->autogluon.timeseries[all]==0.8.2->autogluon==0.8.2) (0.5.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.2->autogluon==0.8.2) (1.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.2->autogluon==0.8.2) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.2->autogluon==0.8.2) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.2->autogluon==0.8.2) (3.4.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.2->autogluon==0.8.2) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.2->autogluon==0.8.2) (3.0.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm<0.10.0,>=0.9.2->autogluon.multimodal==0.8.2->autogluon==0.8.2) (0.4.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch<1.14,>=1.9->autogluon.multimodal==0.8.2->autogluon==0.8.2) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch<1.14,>=1.9->autogluon.multimodal==0.8.2->autogluon==0.8.2) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch<1.14,>=1.9->autogluon.multimodal==0.8.2->autogluon==0.8.2) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch<1.14,>=1.9->autogluon.multimodal==0.8.2->autogluon==0.8.2) (11.7.99)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<4.27.0,>=4.23.0->autogluon.multimodal==0.8.2->autogluon==0.8.2) (0.13.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<4.27.0,>=4.23.0->autogluon.multimodal==0.8.2->autogluon==0.8.2) (0.1.99)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==0.8.2->autogluon==0.8.2) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==0.8.2->autogluon==0.8.2) (0.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==0.8.2->autogluon==0.8.2) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==0.8.2->autogluon==0.8.2) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==0.8.2->autogluon==0.8.2) (3.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->autogluon==0.8.2) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->autogluon==0.8.2) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->autogluon==0.8.2) (1.9.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2->autogluon==0.8.2) (9.0.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.8.2->autogluon==0.8.2) (4.11.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.8.2->autogluon==0.8.2) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.8.2->autogluon==0.8.2) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.8.2->autogluon==0.8.2) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==0.8.2->autogluon==0.8.2) (1.3.1)\n",
            "Requirement already satisfied: nvidia-ml-py>=11.450.129 in /usr/local/lib/python3.10/dist-packages (from gpustat>=1.0.0->ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->autogluon==0.8.2) (12.535.108)\n",
            "Requirement already satisfied: blessed>=1.17.1 in /usr/local/lib/python3.10/dist-packages (from gpustat>=1.0.0->ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->autogluon==0.8.2) (1.20.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->mlforecast<0.7.4,>=0.7.0->autogluon.timeseries[all]==0.8.2->autogluon==0.8.2) (0.39.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (0.10.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (3.3.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.0.24->ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->autogluon==0.8.2) (0.3.7)\n",
            "Requirement already satisfied: platformdirs<4,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.0.24->ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->autogluon==0.8.2) (3.11.0)\n",
            "Requirement already satisfied: ordered-set in /usr/local/lib/python3.10/dist-packages (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->autogluon==0.8.2) (4.1.0)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->autogluon==0.8.2) (0.1.3)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->autogluon==0.8.2) (2.11.1)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->autogluon==0.8.2) (3.19.0)\n",
            "Requirement already satisfied: openxlab in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->autogluon==0.8.2) (0.0.26)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost<1.3,>=1.1->autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (8.2.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->autogluon==0.8.2) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->autogluon==0.8.2) (2.16.1)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->autogluon==0.8.2) (0.2.8)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->autogluon==0.8.2) (1.60.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->autogluon==0.8.2) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.8.2->autogluon==0.8.2) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==0.8.2->autogluon==0.8.2) (3.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->autogluon==0.8.2) (0.1.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.8.2->autogluon==0.8.2) (2.5)\n",
            "Requirement already satisfied: oss2~=2.17.0 in /usr/local/lib/python3.10/dist-packages (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->autogluon==0.8.2) (2.17.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==0.8.2->autogluon==0.8.2) (1.7.1)\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.10/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->autogluon==0.8.2) (1.7)\n",
            "Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->autogluon==0.8.2) (2.16.2)\n",
            "Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /usr/local/lib/python3.10/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->autogluon==0.8.2) (2.14.0)\n",
            "Requirement already satisfied: cryptography>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->autogluon==0.8.2) (41.0.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->autogluon==0.8.2) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->autogluon==0.8.2) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tApLOUtVKaQ",
        "outputId": "37c56e66-8ca8-4e97-aa5c-dae598789f9c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "1T6YTpAM9dwl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6c5PQb4vzNUF"
      },
      "outputs": [],
      "source": [
        "\n",
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "from autogluon.common.utils.utils import setup_outputdir\n",
        "from autogluon.core.utils.loaders import load_pkl\n",
        "from autogluon.core.utils.savers import save_pkl\n",
        "import os.path\n",
        "\n",
        "\"\"\"\n",
        "@author: Lyle\n",
        "\"\"\"\n",
        "\n",
        "class MultilabelPredictor:\n",
        "    \"\"\" Tabular Predictor for predicting multiple columns in table.\n",
        "        Creates multiple TabularPredictor objects which you can also use individually.\n",
        "        You can access the TabularPredictor for a particular label via: `multilabel_predictor.get_predictor(label_i)`\n",
        "\n",
        "        Parameters ---------- labels : List[str] The ith element of this list is the column (i.e. `label`) predicted\n",
        "        by the ith TabularPredictor stored in this object. path : str, default = None Path to directory where models\n",
        "        and intermediate outputs should be saved. If unspecified, a time-stamped folder called \"AutogluonModels/ag-[\n",
        "        TIMESTAMP]\" will be created in the working directory to store all models. Note: To call `fit()` twice and\n",
        "        save all results of each fit, you must specify different `path` locations or don't specify `path` at all.\n",
        "        Otherwise files from first `fit()` will be overwritten by second `fit()`. Caution: when predicting many\n",
        "        labels, this directory may grow large as it needs to store many TabularPredictors. problem_types : List[str],\n",
        "        default = None The ith element is the `problem_type` for the ith TabularPredictor stored in this object.\n",
        "        eval_metrics : List[str], default = None The ith element is the `eval_metric` for the ith TabularPredictor\n",
        "        stored in this object. consider_labels_correlation : bool, default = True Whether the predictions of multiple\n",
        "        labels should account for label correlations or predict each label independently of the others. If True,\n",
        "        the ordering of `labels` may affect resulting accuracy as each label is predicted conditional on the previous\n",
        "        labels appearing earlier in this list (i.e. in an auto-regressive fashion). Set to False if during inference\n",
        "        you may want to individually use just the ith TabularPredictor without predicting all the other labels.\n",
        "        kwargs : Arguments passed into the initialization of each TabularPredictor.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    multi_predictor_file = 'multilabel_predictor.pkl'\n",
        "\n",
        "    def __init__(self, labels, path=None, problem_types=None, eval_metrics=None, consider_labels_correlation=True,\n",
        "                 **kwargs):\n",
        "        self.model_root = None\n",
        "        if len(labels) < 2:\n",
        "            raise ValueError(\n",
        "                \"MultilabelPredictor is only intended for predicting MULTIPLE labels (columns), use TabularPredictor \"\n",
        "                \"for predicting one label (column).\")\n",
        "        if (problem_types is not None) and (len(problem_types) != len(labels)):\n",
        "            raise ValueError(\"If provided, `problem_types` must have same length as `labels`\")\n",
        "        if (eval_metrics is not None) and (len(eval_metrics) != len(labels)):\n",
        "            raise ValueError(\"If provided, `eval_metrics` must have same length as `labels`\")\n",
        "        self.path = setup_outputdir(path, warn_if_exist=False)\n",
        "        self.labels = labels\n",
        "        self.consider_labels_correlation = consider_labels_correlation\n",
        "        self.predictors = {}  # key = label, value = TabularPredictor or str path to the TabularPredictor for this label\n",
        "        if eval_metrics is None:\n",
        "            self.eval_metrics = {}\n",
        "        else:\n",
        "            self.eval_metrics = {labels[i]: eval_metrics[i] for i in range(len(labels))}\n",
        "        problem_type = None\n",
        "        eval_metric = None\n",
        "        for i in range(len(labels)):\n",
        "            label = labels[i]\n",
        "            path_i = self.path + \"Predictor_\" + label\n",
        "            if problem_types is not None:\n",
        "                problem_type = problem_types[i]\n",
        "            if eval_metrics is not None:\n",
        "                eval_metric = eval_metrics[i]\n",
        "            self.predictors[label] = TabularPredictor(label=label, problem_type=problem_type, eval_metric=eval_metric,\n",
        "                                                      path=path_i, **kwargs)\n",
        "\n",
        "    def fit(self, train_data, tuning_data=None, **kwargs):\n",
        "        \"\"\" Fits a separate TabularPredictor to predict each of the labels.\n",
        "\n",
        "            Parameters\n",
        "            ----------\n",
        "            train_data, tuning_data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
        "                See documentation for `TabularPredictor.fit()`.\n",
        "            kwargs :\n",
        "                Arguments passed into the `fit()` call for each TabularPredictor.\n",
        "        \"\"\"\n",
        "        if isinstance(train_data, str):\n",
        "            train_data = TabularDataset(train_data)\n",
        "        if tuning_data is not None and isinstance(tuning_data, str):\n",
        "            tuning_data = TabularDataset(tuning_data)\n",
        "        train_data_og = train_data.copy()\n",
        "        if tuning_data is not None:\n",
        "            tuning_data_og = tuning_data.copy()\n",
        "        else:\n",
        "            tuning_data_og = None\n",
        "        save_metrics = len(self.eval_metrics) == 0\n",
        "        for i in range(len(self.labels)):\n",
        "            label = self.labels[i]\n",
        "            predictor = self.get_predictor(label)\n",
        "            if not self.consider_labels_correlation:\n",
        "                labels_to_drop = [l for l in self.labels if l != label]\n",
        "            else:\n",
        "                labels_to_drop = [self.labels[j] for j in range(i + 1, len(self.labels))]\n",
        "            train_data = train_data_og.drop(labels_to_drop, axis=1)\n",
        "            if tuning_data is not None:\n",
        "                tuning_data = tuning_data_og.drop(labels_to_drop, axis=1)\n",
        "            print(f\"Fitting TabularPredictor for label: {label} ...\")\n",
        "            predictor.fit(train_data=train_data, tuning_data=tuning_data, **kwargs)\n",
        "            self.predictors[label] = predictor.path\n",
        "            if save_metrics:\n",
        "                self.eval_metrics[label] = predictor.eval_metric\n",
        "        self.save()\n",
        "\n",
        "    def predict(self, data, **kwargs):\n",
        "        \"\"\" Returns DataFrame with label columns containing predictions for each label.\n",
        "\n",
        "            Parameters ---------- data : str or autogluon.tabular.TabularDataset or pd.DataFrame Data to make\n",
        "            predictions for. If label columns are present in this data, they will be ignored. See documentation for\n",
        "            `TabularPredictor.predict()`. kwargs : Arguments passed into the predict() call for each TabularPredictor.\n",
        "        \"\"\"\n",
        "        return self._predict(data, as_proba=False, **kwargs)\n",
        "\n",
        "    def predict_proba(self, data, **kwargs):\n",
        "        \"\"\" Returns dict where each key is a label and the corresponding value is the `predict_proba()` output for just that label.\n",
        "\n",
        "            Parameters\n",
        "            ----------\n",
        "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
        "                Data to make predictions for. See documentation for `TabularPredictor.predict()` and `TabularPredictor.predict_proba()`.\n",
        "            kwargs :\n",
        "                Arguments passed into the `predict_proba()` call for each TabularPredictor (also passed into a `predict()` call).\n",
        "        \"\"\"\n",
        "        return self._predict(data, as_proba=True, **kwargs)\n",
        "\n",
        "    def evaluate(self, data, **kwargs):\n",
        "        \"\"\" Returns dict where each key is a label and the corresponding value is the `evaluate()` output for just that label.\n",
        "\n",
        "            Parameters\n",
        "            ----------\n",
        "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
        "                Data to evalate predictions of all labels for, must contain all labels as columns. See documentation for `TabularPredictor.evaluate()`.\n",
        "            kwargs :\n",
        "                Arguments passed into the `evaluate()` call for each TabularPredictor (also passed into the `predict()` call).\n",
        "        \"\"\"\n",
        "        data = self._get_data(data)\n",
        "        eval_dict = {}\n",
        "        for label in self.labels:\n",
        "            print(f\"Evaluating TabularPredictor for label: {label} ...\")\n",
        "            predictor = self.get_predictor(label)\n",
        "            eval_dict[label] = predictor.evaluate(data, **kwargs)\n",
        "            if self.consider_labels_correlation:\n",
        "                data[label] = predictor.predict(data, **kwargs)\n",
        "        return eval_dict\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\" Save MultilabelPredictor to disk. \"\"\"\n",
        "        for label in self.labels:\n",
        "            if not isinstance(self.predictors[label], str):\n",
        "                self.predictors[label] = self.predictors[label].path\n",
        "        save_pkl.save(path=self.path + self.multi_predictor_file, object=self)\n",
        "        print(f\"MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('{self.path}')\")\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, path):\n",
        "        \"\"\" Load MultilabelPredictor from disk `path` previously specified when creating this MultilabelPredictor. \"\"\"\n",
        "        predictor_instance = load_pkl.load(path=os.path.join(path, cls.multi_predictor_file))\n",
        "        predictor_instance.model_root = path\n",
        "        return predictor_instance\n",
        "\n",
        "    def get_predictor(self, label):\n",
        "        \"\"\" Returns TabularPredictor which is used to predict this label. \"\"\"\n",
        "        predictor = self.predictors[label]\n",
        "        if isinstance(predictor, str):\n",
        "            path_elements = predictor.split(\"/\")\n",
        "            path_relative_to_root = path_elements[-2] + \"/\" + path_elements[-1]\n",
        "            return TabularPredictor.load(path=os.path.join(self.model_root, path_relative_to_root))\n",
        "        return predictor\n",
        "\n",
        "    def _get_data(self, data):\n",
        "        if isinstance(data, str):\n",
        "            return TabularDataset(data)\n",
        "        return data.copy()\n",
        "\n",
        "    def _predict(self, data, as_proba=False, **kwargs):\n",
        "        data = self._get_data(data)\n",
        "        if as_proba:\n",
        "            predproba_dict = {}\n",
        "        for label in self.labels:\n",
        "            #             print(f\"Predicting with TabularPredictor for label: {label} ...\")\n",
        "            predictor = self.get_predictor(label)\n",
        "            if as_proba:\n",
        "                predproba_dict[label] = predictor.predict_proba(data, as_multiclass=True, **kwargs)\n",
        "            data[label] = predictor.predict(data, **kwargs)\n",
        "        if not as_proba:\n",
        "            return data[self.labels]\n",
        "        else:\n",
        "            return predproba_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sun Jul 10 12:05:43 2022\n",
        "\n",
        "@author: Lyle\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "ALL_STRUCTURAL_DATASET = \"/content/drive/MyDrive/all_structural_data_aug.csv\"\n",
        "\n",
        "\n",
        "def one_hot_encode_material(data):\n",
        "    data = data.copy()\n",
        "    # One-hot encode the materials\n",
        "    data.loc[:, \"Material\"] = pd.Categorical(data[\"Material\"], categories=[\"Steel\", \"Aluminum\", \"Titanium\"])\n",
        "    mats_oh = pd.get_dummies(data[\"Material\"], prefix=\"Material=\", prefix_sep=\"\")\n",
        "    data.drop([\"Material\"], axis=1, inplace=True)\n",
        "    data = pd.concat([mats_oh, data], axis=1)\n",
        "    return data\n",
        "\n",
        "\n",
        "def load_augmented_framed_dataset():\n",
        "    reg_data = pd.read_csv(ALL_STRUCTURAL_DATASET, index_col=0)\n",
        "\n",
        "    x = reg_data.iloc[:, :-11]\n",
        "\n",
        "    x = one_hot_encode_material(x)\n",
        "\n",
        "    x, x_scaler = scale(x)\n",
        "    y = reg_data.iloc[:, -11:-1]\n",
        "\n",
        "    for col in ['Sim 1 Safety Factor', 'Sim 3 Safety Factor']:\n",
        "        y[col] = 1 / y[col]\n",
        "        y.rename(columns={col: col + \" (Inverted)\"}, inplace=True)\n",
        "    # THIS MODEL HAS BEEN TRAINED ON SIGNED DISPLACEMENT VALUES INSTEAD OF MAGNITUDES\n",
        "    # for col in ['Sim 1 Dropout X Disp.', 'Sim 1 Dropout Y Disp.', 'Sim 1 Bottom Bracket X Disp.',\n",
        "    #             'Sim 1 Bottom Bracket Y Disp.', 'Sim 2 Bottom Bracket Z Disp.', 'Sim 3 Bottom Bracket Y Disp.',\n",
        "    #             'Sim 3 Bottom Bracket X Rot.', 'Model Mass']:\n",
        "    #     y[col] = [np.abs(val) for val in y[col].values]\n",
        "    #     y.rename(columns={col: col + \" Magnitude\"}, inplace=True)\n",
        "    y, y_scaler = scale(y)\n",
        "\n",
        "    return x, y, x_scaler, y_scaler\n",
        "\n",
        "\n",
        "def scale(v):\n",
        "    v_scaler = StandardScaler()\n",
        "    v_scaler.fit(v)\n",
        "    v_scaled_values = v_scaler.transform(v)\n",
        "    new_v = pd.DataFrame(v_scaled_values, columns=v.columns, index=v.index)\n",
        "    return new_v, v_scaler"
      ],
      "metadata": {
        "id": "ClnOq0dr8mVk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_scaled, y_scaled, x_scaler, y_scaler = load_augmented_framed_dataset()\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y_scaled, random_state=2023)\n"
      ],
      "metadata": {
        "id": "G6QftljF9LHm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43cb554c-044e-43ff-98c0-6a849d9f720f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-9467006776f7>:18: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  data.loc[:, \"Material\"] = pd.Categorical(data[\"Material\"], categories=[\"Steel\", \"Aluminum\", \"Titanium\"])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(x_test), len(y_test))\n",
        "len(x_train), len(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "725XVLhbfqKu",
        "outputId": "0b606af0-5ba2-4cb6-f5a9-5fa893fc8ba0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3713 3713\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11138, 11138)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_training_set = pd.concat([x_train, y_train], axis=1)\n",
        "len(full_training_set)"
      ],
      "metadata": {
        "id": "xo-Tltexhttk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27ac2236-e192-4939-f1cb-8fb77d65f851"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11138"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_predictor = MultilabelPredictor(labels=y_scaled.columns)\n",
        "my_predictor.fit(\n",
        "    train_data=full_training_set\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5-vSuEU9RtX",
        "outputId": "62c837ac-f764-4777-fe8b-329881e1ea15"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20231012_051754/Predictor_Sim 1 Dropout X Disp./\"\n",
            "AutoGluon Version:  0.8.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Wed Aug 30 11:19:59 UTC 2023\n",
            "Disk Space Avail:   48.77 GB / 83.96 GB (58.1%)\n",
            "Train Data Rows:    11138\n",
            "Train Data Columns: 39\n",
            "Label Column: Sim 1 Dropout X Disp.\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (12.31357753874557, -5.036857510156917, -0.00664, 0.99526)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11781.79 MB\n",
            "\tTrain Data (Original)  Memory Usage: 3.48 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting TabularPredictor for label: Sim 1 Dropout X Disp. ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 39 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 34 | ['CS Length', 'BB Drop', 'Stack', 'SS E', 'ST Angle', ...]\n",
            "\t\t('int', ['bool']) :  5 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include']\n",
            "\t0.7s = Fit runtime\n",
            "\t39 features in original data used to generate 39 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 3.09 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.82s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 10024, Val Rows: 1114\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': {},\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': {},\n",
            "\t'XGB': {},\n",
            "\t'FASTAI': {},\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-0.7754\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.15s\t = Training   runtime\n",
            "\t0.63s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-0.7507\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.13s\t = Training   runtime\n",
            "\t0.35s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t-0.3461\t = Validation score   (-root_mean_squared_error)\n",
            "\t8.08s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-0.3191\t = Validation score   (-root_mean_squared_error)\n",
            "\t2.28s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-0.3412\t = Validation score   (-root_mean_squared_error)\n",
            "\t75.56s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.3322\t = Validation score   (-root_mean_squared_error)\n",
            "\t14.68s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-0.4121\t = Validation score   (-root_mean_squared_error)\n",
            "\t18.04s\t = Training   runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-0.3477\t = Validation score   (-root_mean_squared_error)\n",
            "\t14.14s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.3342\t = Validation score   (-root_mean_squared_error)\n",
            "\t4.45s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-0.3426\t = Validation score   (-root_mean_squared_error)\n",
            "\t32.78s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t-0.3199\t = Validation score   (-root_mean_squared_error)\n",
            "\t10.21s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t-0.3047\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.43s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 185.21s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231012_051754/Predictor_Sim 1 Dropout X Disp./\")\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20231012_051754/Predictor_Sim 1 Dropout Y Disp./\"\n",
            "AutoGluon Version:  0.8.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Wed Aug 30 11:19:59 UTC 2023\n",
            "Disk Space Avail:   48.29 GB / 83.96 GB (57.5%)\n",
            "Train Data Rows:    11138\n",
            "Train Data Columns: 40\n",
            "Label Column: Sim 1 Dropout Y Disp.\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (4.873152389135353, -14.704521850848263, 0.00634, 0.96242)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11567.19 MB\n",
            "\tTrain Data (Original)  Memory Usage: 3.56 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting TabularPredictor for label: Sim 1 Dropout Y Disp. ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 40 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 35 | ['CS Length', 'BB Drop', 'Stack', 'SS E', 'ST Angle', ...]\n",
            "\t\t('int', ['bool']) :  5 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include']\n",
            "\t0.2s = Fit runtime\n",
            "\t40 features in original data used to generate 40 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 3.17 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.21s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 10024, Val Rows: 1114\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': {},\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': {},\n",
            "\t'XGB': {},\n",
            "\t'FASTAI': {},\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-0.533\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-0.5214\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.410868\n",
            "[2000]\tvalid_set's rmse: 0.407763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.4077\t = Validation score   (-root_mean_squared_error)\n",
            "\t12.94s\t = Training   runtime\n",
            "\t0.34s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.323699\n",
            "[2000]\tvalid_set's rmse: 0.312753\n",
            "[3000]\tvalid_set's rmse: 0.31383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.3125\t = Validation score   (-root_mean_squared_error)\n",
            "\t19.67s\t = Training   runtime\n",
            "\t0.59s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-0.3175\t = Validation score   (-root_mean_squared_error)\n",
            "\t80.24s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.3238\t = Validation score   (-root_mean_squared_error)\n",
            "\t21.58s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-0.3468\t = Validation score   (-root_mean_squared_error)\n",
            "\t19.33s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-0.2421\t = Validation score   (-root_mean_squared_error)\n",
            "\t16.67s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.338\t = Validation score   (-root_mean_squared_error)\n",
            "\t7.77s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-0.3628\t = Validation score   (-root_mean_squared_error)\n",
            "\t23.01s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t-0.3523\t = Validation score   (-root_mean_squared_error)\n",
            "\t16.58s\t = Training   runtime\n",
            "\t0.22s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t-0.2399\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.72s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 223.43s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231012_051754/Predictor_Sim 1 Dropout Y Disp./\")\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20231012_051754/Predictor_Sim 1 Bottom Bracket X Disp./\"\n",
            "AutoGluon Version:  0.8.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Wed Aug 30 11:19:59 UTC 2023\n",
            "Disk Space Avail:   47.80 GB / 83.96 GB (56.9%)\n",
            "Train Data Rows:    11138\n",
            "Train Data Columns: 41\n",
            "Label Column: Sim 1 Bottom Bracket X Disp.\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (12.469725909301927, -4.8756459395290515, -0.00688, 0.99169)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11486.02 MB\n",
            "\tTrain Data (Original)  Memory Usage: 3.65 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting TabularPredictor for label: Sim 1 Bottom Bracket X Disp. ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 41 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 36 | ['CS Length', 'BB Drop', 'Stack', 'SS E', 'ST Angle', ...]\n",
            "\t\t('int', ['bool']) :  5 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include']\n",
            "\t0.2s = Fit runtime\n",
            "\t41 features in original data used to generate 41 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 3.26 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.25s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 10024, Val Rows: 1114\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': {},\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': {},\n",
            "\t'XGB': {},\n",
            "\t'FASTAI': {},\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-0.3186\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-0.3018\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.26s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.17849\n",
            "[2000]\tvalid_set's rmse: 0.176705\n",
            "[3000]\tvalid_set's rmse: 0.176325\n",
            "[4000]\tvalid_set's rmse: 0.176285\n",
            "[5000]\tvalid_set's rmse: 0.176222\n",
            "[6000]\tvalid_set's rmse: 0.17615\n",
            "[7000]\tvalid_set's rmse: 0.176122\n",
            "[8000]\tvalid_set's rmse: 0.176135\n",
            "[9000]\tvalid_set's rmse: 0.176134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.1761\t = Validation score   (-root_mean_squared_error)\n",
            "\t36.31s\t = Training   runtime\n",
            "\t1.08s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-0.1156\t = Validation score   (-root_mean_squared_error)\n",
            "\t3.86s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-0.065\t = Validation score   (-root_mean_squared_error)\n",
            "\t74.62s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.1228\t = Validation score   (-root_mean_squared_error)\n",
            "\t214.39s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-0.0621\t = Validation score   (-root_mean_squared_error)\n",
            "\t16.53s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-0.0569\t = Validation score   (-root_mean_squared_error)\n",
            "\t14.22s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.1141\t = Validation score   (-root_mean_squared_error)\n",
            "\t8.41s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-0.1664\t = Validation score   (-root_mean_squared_error)\n",
            "\t12.69s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t-0.1169\t = Validation score   (-root_mean_squared_error)\n",
            "\t11.63s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t-0.0442\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.4s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 399.1s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231012_051754/Predictor_Sim 1 Bottom Bracket X Disp./\")\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20231012_051754/Predictor_Sim 1 Bottom Bracket Y Disp./\"\n",
            "AutoGluon Version:  0.8.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Wed Aug 30 11:19:59 UTC 2023\n",
            "Disk Space Avail:   47.30 GB / 83.96 GB (56.3%)\n",
            "Train Data Rows:    11138\n",
            "Train Data Columns: 42\n",
            "Label Column: Sim 1 Bottom Bracket Y Disp.\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (5.6847343428469665, -17.037374662996648, 0.00414, 1.00356)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11297.28 MB\n",
            "\tTrain Data (Original)  Memory Usage: 3.74 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 42 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include', ...]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting TabularPredictor for label: Sim 1 Bottom Bracket Y Disp. ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 37 | ['CS Length', 'BB Drop', 'Stack', 'SS E', 'ST Angle', ...]\n",
            "\t\t('int', ['bool']) :  5 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include']\n",
            "\t0.2s = Fit runtime\n",
            "\t42 features in original data used to generate 42 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 3.35 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.2s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 10024, Val Rows: 1114\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': {},\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': {},\n",
            "\t'XGB': {},\n",
            "\t'FASTAI': {},\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-0.3908\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-0.3831\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.35138\n",
            "[2000]\tvalid_set's rmse: 0.347272\n",
            "[3000]\tvalid_set's rmse: 0.346965\n",
            "[4000]\tvalid_set's rmse: 0.346849\n",
            "[5000]\tvalid_set's rmse: 0.346742\n",
            "[6000]\tvalid_set's rmse: 0.34666\n",
            "[7000]\tvalid_set's rmse: 0.346643\n",
            "[8000]\tvalid_set's rmse: 0.346635\n",
            "[9000]\tvalid_set's rmse: 0.346645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.3466\t = Validation score   (-root_mean_squared_error)\n",
            "\t42.96s\t = Training   runtime\n",
            "\t0.88s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-0.2898\t = Validation score   (-root_mean_squared_error)\n",
            "\t3.25s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-0.2351\t = Validation score   (-root_mean_squared_error)\n",
            "\t86.91s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.2848\t = Validation score   (-root_mean_squared_error)\n",
            "\t16.84s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-0.2471\t = Validation score   (-root_mean_squared_error)\n",
            "\t25.19s\t = Training   runtime\n",
            "\t0.27s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-0.071\t = Validation score   (-root_mean_squared_error)\n",
            "\t14.27s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.3202\t = Validation score   (-root_mean_squared_error)\n",
            "\t5.86s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-0.2858\t = Validation score   (-root_mean_squared_error)\n",
            "\t15.36s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.269673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.2695\t = Validation score   (-root_mean_squared_error)\n",
            "\t22.06s\t = Training   runtime\n",
            "\t0.3s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t-0.0691\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.72s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 239.18s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231012_051754/Predictor_Sim 1 Bottom Bracket Y Disp./\")\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20231012_051754/Predictor_Sim 2 Bottom Bracket Z Disp./\"\n",
            "AutoGluon Version:  0.8.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Wed Aug 30 11:19:59 UTC 2023\n",
            "Disk Space Avail:   46.79 GB / 83.96 GB (55.7%)\n",
            "Train Data Rows:    11138\n",
            "Train Data Columns: 43\n",
            "Label Column: Sim 2 Bottom Bracket Z Disp.\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (59.6124648888891, -1.5154313626269182, 0.00088, 1.04073)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11121.94 MB\n",
            "\tTrain Data (Original)  Memory Usage: 3.83 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting TabularPredictor for label: Sim 2 Bottom Bracket Z Disp. ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 43 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 38 | ['CS Length', 'BB Drop', 'Stack', 'SS E', 'ST Angle', ...]\n",
            "\t\t('int', ['bool']) :  5 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include']\n",
            "\t0.2s = Fit runtime\n",
            "\t43 features in original data used to generate 43 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 3.44 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.27s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 10024, Val Rows: 1114\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': {},\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': {},\n",
            "\t'XGB': {},\n",
            "\t'FASTAI': {},\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-0.5173\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-0.4976\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.39s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.273899\n",
            "[2000]\tvalid_set's rmse: 0.270414\n",
            "[3000]\tvalid_set's rmse: 0.268822\n",
            "[4000]\tvalid_set's rmse: 0.268107\n",
            "[5000]\tvalid_set's rmse: 0.26762\n",
            "[6000]\tvalid_set's rmse: 0.267409\n",
            "[7000]\tvalid_set's rmse: 0.267397\n",
            "[8000]\tvalid_set's rmse: 0.26734\n",
            "[9000]\tvalid_set's rmse: 0.267309\n",
            "[10000]\tvalid_set's rmse: 0.267288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.2673\t = Validation score   (-root_mean_squared_error)\n",
            "\t46.36s\t = Training   runtime\n",
            "\t1.54s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-0.281\t = Validation score   (-root_mean_squared_error)\n",
            "\t3.8s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-0.3268\t = Validation score   (-root_mean_squared_error)\n",
            "\t92.61s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.2025\t = Validation score   (-root_mean_squared_error)\n",
            "\t221.19s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-0.2968\t = Validation score   (-root_mean_squared_error)\n",
            "\t19.47s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-0.2434\t = Validation score   (-root_mean_squared_error)\n",
            "\t10.35s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.2427\t = Validation score   (-root_mean_squared_error)\n",
            "\t20.01s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-0.2168\t = Validation score   (-root_mean_squared_error)\n",
            "\t39.04s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t-0.3161\t = Validation score   (-root_mean_squared_error)\n",
            "\t10.32s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t-0.1674\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.56s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 470.98s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231012_051754/Predictor_Sim 2 Bottom Bracket Z Disp./\")\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20231012_051754/Predictor_Sim 3 Bottom Bracket Y Disp./\"\n",
            "AutoGluon Version:  0.8.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Wed Aug 30 11:19:59 UTC 2023\n",
            "Disk Space Avail:   46.27 GB / 83.96 GB (55.1%)\n",
            "Train Data Rows:    11138\n",
            "Train Data Columns: 44\n",
            "Label Column: Sim 3 Bottom Bracket Y Disp.\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (2.6929144951244286, -44.430876897048506, -0.00057, 1.0291)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11093.98 MB\n",
            "\tTrain Data (Original)  Memory Usage: 3.92 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting TabularPredictor for label: Sim 3 Bottom Bracket Y Disp. ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 44 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 39 | ['CS Length', 'BB Drop', 'Stack', 'SS E', 'ST Angle', ...]\n",
            "\t\t('int', ['bool']) :  5 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include']\n",
            "\t0.2s = Fit runtime\n",
            "\t44 features in original data used to generate 44 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 3.53 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.23s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 10024, Val Rows: 1114\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': {},\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': {},\n",
            "\t'XGB': {},\n",
            "\t'FASTAI': {},\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-0.502\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.38s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-0.4896\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.37s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t-0.3875\t = Validation score   (-root_mean_squared_error)\n",
            "\t4.63s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-0.3385\t = Validation score   (-root_mean_squared_error)\n",
            "\t4.44s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-0.4463\t = Validation score   (-root_mean_squared_error)\n",
            "\t104.57s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.3911\t = Validation score   (-root_mean_squared_error)\n",
            "\t225.27s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-0.3228\t = Validation score   (-root_mean_squared_error)\n",
            "\t17.78s\t = Training   runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-0.2629\t = Validation score   (-root_mean_squared_error)\n",
            "\t13.92s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.4897\t = Validation score   (-root_mean_squared_error)\n",
            "\t7.86s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-0.3916\t = Validation score   (-root_mean_squared_error)\n",
            "\t22.26s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t-0.4536\t = Validation score   (-root_mean_squared_error)\n",
            "\t9.66s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t-0.2484\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.68s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 414.46s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231012_051754/Predictor_Sim 3 Bottom Bracket Y Disp./\")\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20231012_051754/Predictor_Sim 3 Bottom Bracket X Rot./\"\n",
            "AutoGluon Version:  0.8.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Wed Aug 30 11:19:59 UTC 2023\n",
            "Disk Space Avail:   45.78 GB / 83.96 GB (54.5%)\n",
            "Train Data Rows:    11138\n",
            "Train Data Columns: 45\n",
            "Label Column: Sim 3 Bottom Bracket X Rot.\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (48.91830899322327, -12.705045869386844, 0.0003, 1.04527)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11122.61 MB\n",
            "\tTrain Data (Original)  Memory Usage: 4.01 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting TabularPredictor for label: Sim 3 Bottom Bracket X Rot. ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 45 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 40 | ['CS Length', 'BB Drop', 'Stack', 'SS E', 'ST Angle', ...]\n",
            "\t\t('int', ['bool']) :  5 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include']\n",
            "\t0.2s = Fit runtime\n",
            "\t45 features in original data used to generate 45 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 3.62 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.25s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 10024, Val Rows: 1114\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': {},\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': {},\n",
            "\t'XGB': {},\n",
            "\t'FASTAI': {},\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-0.6328\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.34s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-0.6042\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.05s\t = Training   runtime\n",
            "\t0.35s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t-0.4177\t = Validation score   (-root_mean_squared_error)\n",
            "\t3.23s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-0.4196\t = Validation score   (-root_mean_squared_error)\n",
            "\t2.73s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-0.4244\t = Validation score   (-root_mean_squared_error)\n",
            "\t105.33s\t = Training   runtime\n",
            "\t0.27s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.3631\t = Validation score   (-root_mean_squared_error)\n",
            "\t226.72s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-0.4267\t = Validation score   (-root_mean_squared_error)\n",
            "\t20.08s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-0.3719\t = Validation score   (-root_mean_squared_error)\n",
            "\t15.39s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.3962\t = Validation score   (-root_mean_squared_error)\n",
            "\t21.42s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-0.4284\t = Validation score   (-root_mean_squared_error)\n",
            "\t17.22s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.381511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.3814\t = Validation score   (-root_mean_squared_error)\n",
            "\t41.49s\t = Training   runtime\n",
            "\t0.41s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t-0.321\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.4s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 458.61s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231012_051754/Predictor_Sim 3 Bottom Bracket X Rot./\")\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20231012_051754/Predictor_Sim 1 Safety Factor (Inverted)/\"\n",
            "AutoGluon Version:  0.8.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Wed Aug 30 11:19:59 UTC 2023\n",
            "Disk Space Avail:   45.30 GB / 83.96 GB (54.0%)\n",
            "Train Data Rows:    11138\n",
            "Train Data Columns: 46\n",
            "Label Column: Sim 1 Safety Factor (Inverted)\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (89.63932055031486, -0.3939172743614557, 0.00474, 1.10523)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11120.72 MB\n",
            "\tTrain Data (Original)  Memory Usage: 4.1 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting TabularPredictor for label: Sim 1 Safety Factor (Inverted) ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 46 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 41 | ['CS Length', 'BB Drop', 'Stack', 'SS E', 'ST Angle', ...]\n",
            "\t\t('int', ['bool']) :  5 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include']\n",
            "\t0.2s = Fit runtime\n",
            "\t46 features in original data used to generate 46 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 3.71 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.21s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 10024, Val Rows: 1114\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': {},\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': {},\n",
            "\t'XGB': {},\n",
            "\t'FASTAI': {},\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-2.6039\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-2.6021\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 2.55636\n",
            "[2000]\tvalid_set's rmse: 2.54448\n",
            "[3000]\tvalid_set's rmse: 2.54223\n",
            "[4000]\tvalid_set's rmse: 2.54138\n",
            "[5000]\tvalid_set's rmse: 2.54082\n",
            "[6000]\tvalid_set's rmse: 2.54058\n",
            "[7000]\tvalid_set's rmse: 2.54046\n",
            "[8000]\tvalid_set's rmse: 2.54039\n",
            "[9000]\tvalid_set's rmse: 2.54029\n",
            "[10000]\tvalid_set's rmse: 2.54031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-2.5403\t = Validation score   (-root_mean_squared_error)\n",
            "\t43.58s\t = Training   runtime\n",
            "\t1.21s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 2.53594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-2.5352\t = Validation score   (-root_mean_squared_error)\n",
            "\t10.51s\t = Training   runtime\n",
            "\t0.24s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-2.575\t = Validation score   (-root_mean_squared_error)\n",
            "\t147.58s\t = Training   runtime\n",
            "\t0.18s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-2.5576\t = Validation score   (-root_mean_squared_error)\n",
            "\t19.25s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-2.5704\t = Validation score   (-root_mean_squared_error)\n",
            "\t21.36s\t = Training   runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-2.1745\t = Validation score   (-root_mean_squared_error)\n",
            "\t9.91s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-2.5669\t = Validation score   (-root_mean_squared_error)\n",
            "\t23.97s\t = Training   runtime\n",
            "\t0.3s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-2.4459\t = Validation score   (-root_mean_squared_error)\n",
            "\t28.96s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t-2.5284\t = Validation score   (-root_mean_squared_error)\n",
            "\t9.45s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t-2.1745\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.39s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 321.11s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231012_051754/Predictor_Sim 1 Safety Factor (Inverted)/\")\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20231012_051754/Predictor_Sim 3 Safety Factor (Inverted)/\"\n",
            "AutoGluon Version:  0.8.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Wed Aug 30 11:19:59 UTC 2023\n",
            "Disk Space Avail:   44.78 GB / 83.96 GB (53.3%)\n",
            "Train Data Rows:    11138\n",
            "Train Data Columns: 47\n",
            "Label Column: Sim 3 Safety Factor (Inverted)\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (87.8663152959725, -0.37389303855875977, 0.00536, 1.11318)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11087.33 MB\n",
            "\tTrain Data (Original)  Memory Usage: 4.19 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting TabularPredictor for label: Sim 3 Safety Factor (Inverted) ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 47 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 42 | ['CS Length', 'BB Drop', 'Stack', 'SS E', 'ST Angle', ...]\n",
            "\t\t('int', ['bool']) :  5 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include']\n",
            "\t0.2s = Fit runtime\n",
            "\t47 features in original data used to generate 47 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 3.8 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.2s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 10024, Val Rows: 1114\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': {},\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': {},\n",
            "\t'XGB': {},\n",
            "\t'FASTAI': {},\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-2.4159\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-2.4108\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 2.5472\n",
            "[2000]\tvalid_set's rmse: 2.53887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-2.538\t = Validation score   (-root_mean_squared_error)\n",
            "\t10.48s\t = Training   runtime\n",
            "\t0.32s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-2.499\t = Validation score   (-root_mean_squared_error)\n",
            "\t5.77s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-2.4316\t = Validation score   (-root_mean_squared_error)\n",
            "\t121.13s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-2.5459\t = Validation score   (-root_mean_squared_error)\n",
            "\t15.58s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-2.3696\t = Validation score   (-root_mean_squared_error)\n",
            "\t19.94s\t = Training   runtime\n",
            "\t0.27s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 3: early stopping\n",
            "\t-0.6587\t = Validation score   (-root_mean_squared_error)\n",
            "\t11.46s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-2.4659\t = Validation score   (-root_mean_squared_error)\n",
            "\t7.8s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-2.2413\t = Validation score   (-root_mean_squared_error)\n",
            "\t44.17s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t-2.5164\t = Validation score   (-root_mean_squared_error)\n",
            "\t16.28s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t-0.6541\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.72s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 257.01s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231012_051754/Predictor_Sim 3 Safety Factor (Inverted)/\")\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20231012_051754/Predictor_Model Mass/\"\n",
            "AutoGluon Version:  0.8.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Wed Aug 30 11:19:59 UTC 2023\n",
            "Disk Space Avail:   44.29 GB / 83.96 GB (52.8%)\n",
            "Train Data Rows:    11138\n",
            "Train Data Columns: 48\n",
            "Label Column: Model Mass\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (6.589862539032262, -1.6897076835673173, 0.0003, 1.0019)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11024.68 MB\n",
            "\tTrain Data (Original)  Memory Usage: 4.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting TabularPredictor for label: Model Mass ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 48 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 43 | ['CS Length', 'BB Drop', 'Stack', 'SS E', 'ST Angle', ...]\n",
            "\t\t('int', ['bool']) :  5 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include']\n",
            "\t0.2s = Fit runtime\n",
            "\t48 features in original data used to generate 48 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 3.89 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.27s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 10024, Val Rows: 1114\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': {},\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': {},\n",
            "\t'XGB': {},\n",
            "\t'FASTAI': {},\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-0.4369\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-0.3819\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.130339\n",
            "[2000]\tvalid_set's rmse: 0.121286\n",
            "[3000]\tvalid_set's rmse: 0.118726\n",
            "[4000]\tvalid_set's rmse: 0.117482\n",
            "[5000]\tvalid_set's rmse: 0.117009\n",
            "[6000]\tvalid_set's rmse: 0.116717\n",
            "[7000]\tvalid_set's rmse: 0.116537\n",
            "[8000]\tvalid_set's rmse: 0.11647\n",
            "[9000]\tvalid_set's rmse: 0.116422\n",
            "[10000]\tvalid_set's rmse: 0.1164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.1164\t = Validation score   (-root_mean_squared_error)\n",
            "\t45.2s\t = Training   runtime\n",
            "\t1.22s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.137374\n",
            "[2000]\tvalid_set's rmse: 0.13594\n",
            "[3000]\tvalid_set's rmse: 0.135669\n",
            "[4000]\tvalid_set's rmse: 0.135432\n",
            "[5000]\tvalid_set's rmse: 0.135351\n",
            "[6000]\tvalid_set's rmse: 0.135316\n",
            "[7000]\tvalid_set's rmse: 0.135304\n",
            "[8000]\tvalid_set's rmse: 0.135294\n",
            "[9000]\tvalid_set's rmse: 0.135288\n",
            "[10000]\tvalid_set's rmse: 0.135284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.1353\t = Validation score   (-root_mean_squared_error)\n",
            "\t64.87s\t = Training   runtime\n",
            "\t1.26s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-0.2241\t = Validation score   (-root_mean_squared_error)\n",
            "\t94.44s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.1099\t = Validation score   (-root_mean_squared_error)\n",
            "\t243.06s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-0.2043\t = Validation score   (-root_mean_squared_error)\n",
            "\t19.78s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-0.1253\t = Validation score   (-root_mean_squared_error)\n",
            "\t12.47s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.1416\t = Validation score   (-root_mean_squared_error)\n",
            "\t29.69s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-0.1491\t = Validation score   (-root_mean_squared_error)\n",
            "\t23.74s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.144699\n",
            "[2000]\tvalid_set's rmse: 0.144461\n",
            "[3000]\tvalid_set's rmse: 0.144442\n",
            "[4000]\tvalid_set's rmse: 0.144439\n",
            "[5000]\tvalid_set's rmse: 0.144439\n",
            "[6000]\tvalid_set's rmse: 0.144438\n",
            "[7000]\tvalid_set's rmse: 0.144438\n",
            "[8000]\tvalid_set's rmse: 0.144438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.1444\t = Validation score   (-root_mean_squared_error)\n",
            "\t185.42s\t = Training   runtime\n",
            "\t1.48s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t-0.1018\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.69s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 735.68s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231012_051754/Predictor_Model Mass/\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('AutogluonModels/ag-20231012_051754/')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_predictor = MultilabelPredictor.load(\"AutogluonModels/ag-20231012_051754/\")\n",
        "predictions = my_predictor.predict(x_test)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "\n",
        "r2, mse, mae"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdQjKO1ZhGuz",
        "outputId": "555c9b85-3e91-4d00-9d5a-f105232a1f66"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6930220830194771, 0.1826461079600396, 0.12257666253981998)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive(\"trained-model\", \"zip\", \"/content/AutogluonModels\")\n"
      ],
      "metadata": {
        "id": "yHX6e5pJ-KdH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f82fc5f4-70bb-4383-b8b1-32abdb31f92e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/trained-model.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4-uVflVSDr1E"
      }
    }
  ]
}