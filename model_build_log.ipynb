{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install autogluon==0.7.0\n"
      ],
      "metadata": {
        "id": "1GRS_nKG6JQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "1T6YTpAM9dwl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6c5PQb4vzNUF"
      },
      "outputs": [],
      "source": [
        "\n",
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "from autogluon.common.utils.utils import setup_outputdir\n",
        "from autogluon.core.utils.loaders import load_pkl\n",
        "from autogluon.core.utils.savers import save_pkl\n",
        "import os.path\n",
        "\n",
        "\"\"\"\n",
        "@author: Lyle\n",
        "\"\"\"\n",
        "\n",
        "class MultilabelPredictor:\n",
        "    \"\"\" Tabular Predictor for predicting multiple columns in table.\n",
        "        Creates multiple TabularPredictor objects which you can also use individually.\n",
        "        You can access the TabularPredictor for a particular label via: `multilabel_predictor.get_predictor(label_i)`\n",
        "\n",
        "        Parameters ---------- labels : List[str] The ith element of this list is the column (i.e. `label`) predicted\n",
        "        by the ith TabularPredictor stored in this object. path : str, default = None Path to directory where models\n",
        "        and intermediate outputs should be saved. If unspecified, a time-stamped folder called \"AutogluonModels/ag-[\n",
        "        TIMESTAMP]\" will be created in the working directory to store all models. Note: To call `fit()` twice and\n",
        "        save all results of each fit, you must specify different `path` locations or don't specify `path` at all.\n",
        "        Otherwise files from first `fit()` will be overwritten by second `fit()`. Caution: when predicting many\n",
        "        labels, this directory may grow large as it needs to store many TabularPredictors. problem_types : List[str],\n",
        "        default = None The ith element is the `problem_type` for the ith TabularPredictor stored in this object.\n",
        "        eval_metrics : List[str], default = None The ith element is the `eval_metric` for the ith TabularPredictor\n",
        "        stored in this object. consider_labels_correlation : bool, default = True Whether the predictions of multiple\n",
        "        labels should account for label correlations or predict each label independently of the others. If True,\n",
        "        the ordering of `labels` may affect resulting accuracy as each label is predicted conditional on the previous\n",
        "        labels appearing earlier in this list (i.e. in an auto-regressive fashion). Set to False if during inference\n",
        "        you may want to individually use just the ith TabularPredictor without predicting all the other labels.\n",
        "        kwargs : Arguments passed into the initialization of each TabularPredictor.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    multi_predictor_file = 'multilabel_predictor.pkl'\n",
        "\n",
        "    def __init__(self, labels, path=None, problem_types=None, eval_metrics=None, consider_labels_correlation=True,\n",
        "                 **kwargs):\n",
        "        self.model_root = None\n",
        "        if len(labels) < 2:\n",
        "            raise ValueError(\n",
        "                \"MultilabelPredictor is only intended for predicting MULTIPLE labels (columns), use TabularPredictor \"\n",
        "                \"for predicting one label (column).\")\n",
        "        if (problem_types is not None) and (len(problem_types) != len(labels)):\n",
        "            raise ValueError(\"If provided, `problem_types` must have same length as `labels`\")\n",
        "        if (eval_metrics is not None) and (len(eval_metrics) != len(labels)):\n",
        "            raise ValueError(\"If provided, `eval_metrics` must have same length as `labels`\")\n",
        "        self.path = setup_outputdir(path, warn_if_exist=False)\n",
        "        self.labels = labels\n",
        "        self.consider_labels_correlation = consider_labels_correlation\n",
        "        self.predictors = {}  # key = label, value = TabularPredictor or str path to the TabularPredictor for this label\n",
        "        if eval_metrics is None:\n",
        "            self.eval_metrics = {}\n",
        "        else:\n",
        "            self.eval_metrics = {labels[i]: eval_metrics[i] for i in range(len(labels))}\n",
        "        problem_type = None\n",
        "        eval_metric = None\n",
        "        for i in range(len(labels)):\n",
        "            label = labels[i]\n",
        "            path_i = self.path + \"Predictor_\" + label\n",
        "            if problem_types is not None:\n",
        "                problem_type = problem_types[i]\n",
        "            if eval_metrics is not None:\n",
        "                eval_metric = eval_metrics[i]\n",
        "            self.predictors[label] = TabularPredictor(label=label, problem_type=problem_type, eval_metric=eval_metric,\n",
        "                                                      path=path_i, **kwargs)\n",
        "\n",
        "    def fit(self, train_data, tuning_data=None, **kwargs):\n",
        "        \"\"\" Fits a separate TabularPredictor to predict each of the labels.\n",
        "\n",
        "            Parameters\n",
        "            ----------\n",
        "            train_data, tuning_data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
        "                See documentation for `TabularPredictor.fit()`.\n",
        "            kwargs :\n",
        "                Arguments passed into the `fit()` call for each TabularPredictor.\n",
        "        \"\"\"\n",
        "        if isinstance(train_data, str):\n",
        "            train_data = TabularDataset(train_data)\n",
        "        if tuning_data is not None and isinstance(tuning_data, str):\n",
        "            tuning_data = TabularDataset(tuning_data)\n",
        "        train_data_og = train_data.copy()\n",
        "        if tuning_data is not None:\n",
        "            tuning_data_og = tuning_data.copy()\n",
        "        else:\n",
        "            tuning_data_og = None\n",
        "        save_metrics = len(self.eval_metrics) == 0\n",
        "        for i in range(len(self.labels)):\n",
        "            label = self.labels[i]\n",
        "            predictor = self.get_predictor(label)\n",
        "            if not self.consider_labels_correlation:\n",
        "                labels_to_drop = [l for l in self.labels if l != label]\n",
        "            else:\n",
        "                labels_to_drop = [self.labels[j] for j in range(i + 1, len(self.labels))]\n",
        "            train_data = train_data_og.drop(labels_to_drop, axis=1)\n",
        "            if tuning_data is not None:\n",
        "                tuning_data = tuning_data_og.drop(labels_to_drop, axis=1)\n",
        "            print(f\"Fitting TabularPredictor for label: {label} ...\")\n",
        "            predictor.fit(train_data=train_data, tuning_data=tuning_data, **kwargs)\n",
        "            self.predictors[label] = predictor.path\n",
        "            if save_metrics:\n",
        "                self.eval_metrics[label] = predictor.eval_metric\n",
        "        self.save()\n",
        "\n",
        "    def predict(self, data, **kwargs):\n",
        "        \"\"\" Returns DataFrame with label columns containing predictions for each label.\n",
        "\n",
        "            Parameters ---------- data : str or autogluon.tabular.TabularDataset or pd.DataFrame Data to make\n",
        "            predictions for. If label columns are present in this data, they will be ignored. See documentation for\n",
        "            `TabularPredictor.predict()`. kwargs : Arguments passed into the predict() call for each TabularPredictor.\n",
        "        \"\"\"\n",
        "        return self._predict(data, as_proba=False, **kwargs)\n",
        "\n",
        "    def predict_proba(self, data, **kwargs):\n",
        "        \"\"\" Returns dict where each key is a label and the corresponding value is the `predict_proba()` output for just that label.\n",
        "\n",
        "            Parameters\n",
        "            ----------\n",
        "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
        "                Data to make predictions for. See documentation for `TabularPredictor.predict()` and `TabularPredictor.predict_proba()`.\n",
        "            kwargs :\n",
        "                Arguments passed into the `predict_proba()` call for each TabularPredictor (also passed into a `predict()` call).\n",
        "        \"\"\"\n",
        "        return self._predict(data, as_proba=True, **kwargs)\n",
        "\n",
        "    def evaluate(self, data, **kwargs):\n",
        "        \"\"\" Returns dict where each key is a label and the corresponding value is the `evaluate()` output for just that label.\n",
        "\n",
        "            Parameters\n",
        "            ----------\n",
        "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
        "                Data to evalate predictions of all labels for, must contain all labels as columns. See documentation for `TabularPredictor.evaluate()`.\n",
        "            kwargs :\n",
        "                Arguments passed into the `evaluate()` call for each TabularPredictor (also passed into the `predict()` call).\n",
        "        \"\"\"\n",
        "        data = self._get_data(data)\n",
        "        eval_dict = {}\n",
        "        for label in self.labels:\n",
        "            print(f\"Evaluating TabularPredictor for label: {label} ...\")\n",
        "            predictor = self.get_predictor(label)\n",
        "            eval_dict[label] = predictor.evaluate(data, **kwargs)\n",
        "            if self.consider_labels_correlation:\n",
        "                data[label] = predictor.predict(data, **kwargs)\n",
        "        return eval_dict\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\" Save MultilabelPredictor to disk. \"\"\"\n",
        "        for label in self.labels:\n",
        "            if not isinstance(self.predictors[label], str):\n",
        "                self.predictors[label] = self.predictors[label].path\n",
        "        save_pkl.save(path=self.path + self.multi_predictor_file, object=self)\n",
        "        print(f\"MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('{self.path}')\")\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, path):\n",
        "        \"\"\" Load MultilabelPredictor from disk `path` previously specified when creating this MultilabelPredictor. \"\"\"\n",
        "        predictor_instance = load_pkl.load(path=os.path.join(path, cls.multi_predictor_file))\n",
        "        predictor_instance.model_root = path\n",
        "        return predictor_instance\n",
        "\n",
        "    def get_predictor(self, label):\n",
        "        \"\"\" Returns TabularPredictor which is used to predict this label. \"\"\"\n",
        "        predictor = self.predictors[label]\n",
        "        if isinstance(predictor, str):\n",
        "            path_elements = predictor.split(\"/\")\n",
        "            path_relative_to_root = path_elements[-2] + \"/\" + path_elements[-1]\n",
        "            return TabularPredictor.load(path=os.path.join(self.model_root, path_relative_to_root))\n",
        "        return predictor\n",
        "\n",
        "    def _get_data(self, data):\n",
        "        if isinstance(data, str):\n",
        "            return TabularDataset(data)\n",
        "        return data.copy()\n",
        "\n",
        "    def _predict(self, data, as_proba=False, **kwargs):\n",
        "        data = self._get_data(data)\n",
        "        if as_proba:\n",
        "            predproba_dict = {}\n",
        "        for label in self.labels:\n",
        "            #             print(f\"Predicting with TabularPredictor for label: {label} ...\")\n",
        "            predictor = self.get_predictor(label)\n",
        "            if as_proba:\n",
        "                predproba_dict[label] = predictor.predict_proba(data, as_multiclass=True, **kwargs)\n",
        "            data[label] = predictor.predict(data, **kwargs)\n",
        "        if not as_proba:\n",
        "            return data[self.labels]\n",
        "        else:\n",
        "            return predproba_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tApLOUtVKaQ",
        "outputId": "9d58379f-1971-49e2-9e51-1eb9c4801799"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sun Jul 10 12:05:43 2022\n",
        "\n",
        "@author: Lyle\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "ALL_STRUCTURAL_DATASET = \"/content/drive/MyDrive/all_structural_data_aug.csv\"\n",
        "\n",
        "\n",
        "def one_hot_encode_material(data):\n",
        "    data = data.copy()\n",
        "    # One-hot encode the materials\n",
        "    data.loc[:, \"Material\"] = pd.Categorical(data[\"Material\"], categories=[\"Steel\", \"Aluminum\", \"Titanium\"])\n",
        "    mats_oh = pd.get_dummies(data[\"Material\"], prefix=\"Material=\", prefix_sep=\"\")\n",
        "    data.drop([\"Material\"], axis=1, inplace=True)\n",
        "    data = pd.concat([mats_oh, data], axis=1)\n",
        "    return data\n",
        "\n",
        "\n",
        "def load_augmented_framed_dataset():\n",
        "    reg_data = pd.read_csv(ALL_STRUCTURAL_DATASET, index_col=0)\n",
        "\n",
        "    x = reg_data.iloc[:, :-11]\n",
        "\n",
        "    x = one_hot_encode_material(x)\n",
        "\n",
        "    x, x_scaler = scale(x)\n",
        "    y = reg_data.iloc[:, -11:-1]\n",
        "\n",
        "    for col in ['Sim 1 Safety Factor', 'Sim 3 Safety Factor']:\n",
        "        y[col] = 1 / y[col]\n",
        "        y.rename(columns={col: col + \" (Inverted)\"}, inplace=True)\n",
        "    for col in ['Sim 1 Dropout X Disp.', 'Sim 1 Dropout Y Disp.', 'Sim 1 Bottom Bracket X Disp.',\n",
        "                'Sim 1 Bottom Bracket Y Disp.', 'Sim 2 Bottom Bracket Z Disp.', 'Sim 3 Bottom Bracket Y Disp.',\n",
        "                'Sim 3 Bottom Bracket X Rot.', 'Model Mass']:\n",
        "        y[col] = [np.abs(val) for val in y[col].values]\n",
        "        y.rename(columns={col: col + \" Magnitude\"}, inplace=True)\n",
        "    y, y_scaler = scale(y)\n",
        "\n",
        "    return x, y, x_scaler, y_scaler\n",
        "\n",
        "\n",
        "def scale(v):\n",
        "    v_scaler = StandardScaler()\n",
        "    v_scaler.fit(v)\n",
        "    v_scaled_values = v_scaler.transform(v)\n",
        "    new_v = pd.DataFrame(v_scaled_values, columns=v.columns, index=v.index)\n",
        "    return new_v, v_scaler"
      ],
      "metadata": {
        "id": "ClnOq0dr8mVk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_scaled, y_scaled, x_scaler, y_scaler = load_augmented_framed_dataset()\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y_scaled, random_state=2023)\n"
      ],
      "metadata": {
        "id": "G6QftljF9LHm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf8dd3ca-6ff2-495b-b2e0-a66f0341db91"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-8a703e428e7d>:18: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  data.loc[:, \"Material\"] = pd.Categorical(data[\"Material\"], categories=[\"Steel\", \"Aluminum\", \"Titanium\"])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(x_test), len(y_test))\n",
        "len(x_train), len(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "725XVLhbfqKu",
        "outputId": "b02c6a31-6995-4018-e6e5-0bc1e69528d0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3713 3713\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11138, 11138)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_training_set = pd.concat([x_train, y_train], axis=1)\n",
        "len(full_training_set)"
      ],
      "metadata": {
        "id": "xo-Tltexhttk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93a47acb-49ad-4f0d-96a6-6d65a3d7bdbf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11138"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_predictor = MultilabelPredictor(labels=y_scaled.columns)\n",
        "my_predictor.fit(\n",
        "    train_data=full_training_set\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5-vSuEU9RtX",
        "outputId": "c720fb56-8e90-43cd-d4fb-e84ebb6ec2b9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230311_154304/Predictor_Sim 1 Dropout X Disp. Magnitude/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.9.16\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    11138\n",
            "Train Data Columns: 39\n",
            "Label Column: Sim 1 Dropout X Disp. Magnitude\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (14.664168867583603, -0.8695634632320092, -0.00307, 0.9914)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11611.81 MB\n",
            "\tTrain Data (Original)  Memory Usage: 3.48 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting TabularPredictor for label: Sim 1 Dropout X Disp. Magnitude ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 39 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 34 | ['CS Length', 'BB Drop', 'Stack', 'SS E', 'ST Angle', ...]\n",
            "\t\t('int', ['bool']) :  5 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include']\n",
            "\t0.2s = Fit runtime\n",
            "\t39 features in original data used to generate 39 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 3.09 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.2s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 10024, Val Rows: 1114\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-0.7769\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.71s\t = Training   runtime\n",
            "\t0.36s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-0.7531\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.73s\t = Training   runtime\n",
            "\t0.28s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.356845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.355\t = Validation score   (-root_mean_squared_error)\n",
            "\t9.55s\t = Training   runtime\n",
            "\t0.13s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-0.3369\t = Validation score   (-root_mean_squared_error)\n",
            "\t6.78s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-0.3869\t = Validation score   (-root_mean_squared_error)\n",
            "\t78.31s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.35\t = Validation score   (-root_mean_squared_error)\n",
            "\t16.44s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-0.4165\t = Validation score   (-root_mean_squared_error)\n",
            "\t19.08s\t = Training   runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-0.3167\t = Validation score   (-root_mean_squared_error)\n",
            "\t16.5s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.3625\t = Validation score   (-root_mean_squared_error)\n",
            "\t5.86s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-0.3432\t = Validation score   (-root_mean_squared_error)\n",
            "\t52.42s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t-0.352\t = Validation score   (-root_mean_squared_error)\n",
            "\t11.44s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t-0.28\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.44s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 221.77s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230311_154304/Predictor_Sim 1 Dropout X Disp. Magnitude/\")\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230311_154304/Predictor_Sim 1 Dropout Y Disp. Magnitude/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.9.16\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    11138\n",
            "Train Data Columns: 40\n",
            "Label Column: Sim 1 Dropout Y Disp. Magnitude\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (16.915383476911376, -0.7819693293792167, -0.00432, 0.94789)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11444.04 MB\n",
            "\tTrain Data (Original)  Memory Usage: 3.56 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 40 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting TabularPredictor for label: Sim 1 Dropout Y Disp. Magnitude ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t\t('float', [])     : 35 | ['CS Length', 'BB Drop', 'Stack', 'SS E', 'ST Angle', ...]\n",
            "\t\t('int', ['bool']) :  5 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include']\n",
            "\t0.1s = Fit runtime\n",
            "\t40 features in original data used to generate 40 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 3.17 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.19s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 10024, Val Rows: 1114\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-0.5667\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-0.5568\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.457226\n",
            "[2000]\tvalid_set's rmse: 0.451328\n",
            "[3000]\tvalid_set's rmse: 0.449558\n",
            "[4000]\tvalid_set's rmse: 0.449334\n",
            "[5000]\tvalid_set's rmse: 0.449241\n",
            "[6000]\tvalid_set's rmse: 0.449095\n",
            "[7000]\tvalid_set's rmse: 0.449104\n",
            "[8000]\tvalid_set's rmse: 0.449099\n",
            "[9000]\tvalid_set's rmse: 0.449098\n",
            "[10000]\tvalid_set's rmse: 0.449107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.4491\t = Validation score   (-root_mean_squared_error)\n",
            "\t43.0s\t = Training   runtime\n",
            "\t0.97s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-0.3687\t = Validation score   (-root_mean_squared_error)\n",
            "\t4.76s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-0.3978\t = Validation score   (-root_mean_squared_error)\n",
            "\t86.48s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.3514\t = Validation score   (-root_mean_squared_error)\n",
            "\t51.41s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-0.4065\t = Validation score   (-root_mean_squared_error)\n",
            "\t21.93s\t = Training   runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-0.2072\t = Validation score   (-root_mean_squared_error)\n",
            "\t15.94s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.3788\t = Validation score   (-root_mean_squared_error)\n",
            "\t7.16s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-0.4069\t = Validation score   (-root_mean_squared_error)\n",
            "\t21.15s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.398831\n",
            "[2000]\tvalid_set's rmse: 0.398723\n",
            "[3000]\tvalid_set's rmse: 0.398723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.3987\t = Validation score   (-root_mean_squared_error)\n",
            "\t59.29s\t = Training   runtime\n",
            "\t0.7s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t-0.2072\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.72s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 320.01s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230311_154304/Predictor_Sim 1 Dropout Y Disp. Magnitude/\")\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230311_154304/Predictor_Sim 1 Bottom Bracket X Disp. Magnitude/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.9.16\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    11138\n",
            "Train Data Columns: 41\n",
            "Label Column: Sim 1 Bottom Bracket X Disp. Magnitude\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (14.626663035683388, -0.8542586608786552, -0.00354, 0.98659)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11294.4 MB\n",
            "\tTrain Data (Original)  Memory Usage: 3.65 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting TabularPredictor for label: Sim 1 Bottom Bracket X Disp. Magnitude ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 41 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 36 | ['CS Length', 'BB Drop', 'Stack', 'SS E', 'ST Angle', ...]\n",
            "\t\t('int', ['bool']) :  5 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include']\n",
            "\t0.2s = Fit runtime\n",
            "\t41 features in original data used to generate 41 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 3.26 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.24s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 10024, Val Rows: 1114\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-0.3211\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.38s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-0.306\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.05s\t = Training   runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t-0.2194\t = Validation score   (-root_mean_squared_error)\n",
            "\t5.43s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-0.1024\t = Validation score   (-root_mean_squared_error)\n",
            "\t8.59s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-0.0717\t = Validation score   (-root_mean_squared_error)\n",
            "\t75.19s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.1276\t = Validation score   (-root_mean_squared_error)\n",
            "\t219.21s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-0.0712\t = Validation score   (-root_mean_squared_error)\n",
            "\t22.99s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-0.0516\t = Validation score   (-root_mean_squared_error)\n",
            "\t11.12s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.1238\t = Validation score   (-root_mean_squared_error)\n",
            "\t9.11s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-0.1261\t = Validation score   (-root_mean_squared_error)\n",
            "\t22.46s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.124837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.1248\t = Validation score   (-root_mean_squared_error)\n",
            "\t28.16s\t = Training   runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t-0.0435\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.39s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 406.83s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230311_154304/Predictor_Sim 1 Bottom Bracket X Disp. Magnitude/\")\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230311_154304/Predictor_Sim 1 Bottom Bracket Y Disp. Magnitude/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.9.16\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    11138\n",
            "Train Data Columns: 42\n",
            "Label Column: Sim 1 Bottom Bracket Y Disp. Magnitude\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (19.807275809958643, -0.8127931135674047, -0.00156, 1.00369)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11196.97 MB\n",
            "\tTrain Data (Original)  Memory Usage: 3.74 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 42 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 37 | ['CS Length', 'BB Drop', 'Stack', 'SS E', 'ST Angle', ...]\n",
            "\t\t('int', ['bool']) :  5 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include']\n",
            "\t0.2s = Fit runtime\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting TabularPredictor for label: Sim 1 Bottom Bracket Y Disp. Magnitude ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t42 features in original data used to generate 42 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 3.35 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.19s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 10024, Val Rows: 1114\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-0.4072\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-0.4014\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.42825\n",
            "[2000]\tvalid_set's rmse: 0.424594\n",
            "[3000]\tvalid_set's rmse: 0.424182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.4241\t = Validation score   (-root_mean_squared_error)\n",
            "\t16.21s\t = Training   runtime\n",
            "\t0.45s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-0.3329\t = Validation score   (-root_mean_squared_error)\n",
            "\t5.19s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-0.2823\t = Validation score   (-root_mean_squared_error)\n",
            "\t84.05s\t = Training   runtime\n",
            "\t0.28s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.3371\t = Validation score   (-root_mean_squared_error)\n",
            "\t9.76s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-0.2986\t = Validation score   (-root_mean_squared_error)\n",
            "\t19.31s\t = Training   runtime\n",
            "\t0.28s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-0.1444\t = Validation score   (-root_mean_squared_error)\n",
            "\t15.08s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.353\t = Validation score   (-root_mean_squared_error)\n",
            "\t8.39s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-0.3174\t = Validation score   (-root_mean_squared_error)\n",
            "\t25.02s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.296257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.2962\t = Validation score   (-root_mean_squared_error)\n",
            "\t31.63s\t = Training   runtime\n",
            "\t0.34s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t-0.1439\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.41s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 219.75s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230311_154304/Predictor_Sim 1 Bottom Bracket Y Disp. Magnitude/\")\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230311_154304/Predictor_Sim 2 Bottom Bracket Z Disp. Magnitude/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.9.16\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    11138\n",
            "Train Data Columns: 43\n",
            "Label Column: Sim 2 Bottom Bracket Z Disp. Magnitude\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (59.615916586568815, -1.1281485873850685, 0.00089, 1.04071)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11156.61 MB\n",
            "\tTrain Data (Original)  Memory Usage: 3.83 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 43 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 38 | ['CS Length', 'BB Drop', 'Stack', 'SS E', 'ST Angle', ...]\n",
            "\t\t('int', ['bool']) :  5 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include']\n",
            "\t0.1s = Fit runtime\n",
            "\t43 features in original data used to generate 43 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 3.44 MB (0.0% of available memory)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting TabularPredictor for label: Sim 2 Bottom Bracket Z Disp. Magnitude ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Data preprocessing and feature engineering runtime = 0.18s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 10024, Val Rows: 1114\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-0.5513\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-0.5319\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.263438\n",
            "[2000]\tvalid_set's rmse: 0.258474\n",
            "[3000]\tvalid_set's rmse: 0.2562\n",
            "[4000]\tvalid_set's rmse: 0.255452\n",
            "[5000]\tvalid_set's rmse: 0.254999\n",
            "[6000]\tvalid_set's rmse: 0.254737\n",
            "[7000]\tvalid_set's rmse: 0.254693\n",
            "[8000]\tvalid_set's rmse: 0.254678\n",
            "[9000]\tvalid_set's rmse: 0.254656\n",
            "[10000]\tvalid_set's rmse: 0.254631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.2546\t = Validation score   (-root_mean_squared_error)\n",
            "\t43.12s\t = Training   runtime\n",
            "\t1.66s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-0.2639\t = Validation score   (-root_mean_squared_error)\n",
            "\t5.27s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-0.3525\t = Validation score   (-root_mean_squared_error)\n",
            "\t86.49s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.1883\t = Validation score   (-root_mean_squared_error)\n",
            "\t221.57s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-0.3359\t = Validation score   (-root_mean_squared_error)\n",
            "\t19.21s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-0.2463\t = Validation score   (-root_mean_squared_error)\n",
            "\t11.59s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.2474\t = Validation score   (-root_mean_squared_error)\n",
            "\t31.79s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-0.224\t = Validation score   (-root_mean_squared_error)\n",
            "\t31.15s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.313272\n",
            "[2000]\tvalid_set's rmse: 0.312932\n",
            "[3000]\tvalid_set's rmse: 0.31292\n",
            "[4000]\tvalid_set's rmse: 0.31292\n",
            "[5000]\tvalid_set's rmse: 0.31292\n",
            "[6000]\tvalid_set's rmse: 0.312919\n",
            "[7000]\tvalid_set's rmse: 0.312919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.3129\t = Validation score   (-root_mean_squared_error)\n",
            "\t160.13s\t = Training   runtime\n",
            "\t1.35s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t-0.1617\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.71s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 625.27s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230311_154304/Predictor_Sim 2 Bottom Bracket Z Disp. Magnitude/\")\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230311_154304/Predictor_Sim 3 Bottom Bracket Y Disp. Magnitude/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.9.16\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    11138\n",
            "Train Data Columns: 44\n",
            "Label Column: Sim 3 Bottom Bracket Y Disp. Magnitude\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (44.45470937362392, -0.8985467596700323, 0.0007, 1.02902)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11109.11 MB\n",
            "\tTrain Data (Original)  Memory Usage: 3.92 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting TabularPredictor for label: Sim 3 Bottom Bracket Y Disp. Magnitude ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 44 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 39 | ['CS Length', 'BB Drop', 'Stack', 'SS E', 'ST Angle', ...]\n",
            "\t\t('int', ['bool']) :  5 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include']\n",
            "\t0.2s = Fit runtime\n",
            "\t44 features in original data used to generate 44 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 3.53 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.24s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 10024, Val Rows: 1114\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-0.5122\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.36s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-0.501\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.06s\t = Training   runtime\n",
            "\t0.24s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.375837\n",
            "[2000]\tvalid_set's rmse: 0.368725\n",
            "[3000]\tvalid_set's rmse: 0.367026\n",
            "[4000]\tvalid_set's rmse: 0.366212\n",
            "[5000]\tvalid_set's rmse: 0.365892\n",
            "[6000]\tvalid_set's rmse: 0.365705\n",
            "[7000]\tvalid_set's rmse: 0.365667\n",
            "[8000]\tvalid_set's rmse: 0.365578\n",
            "[9000]\tvalid_set's rmse: 0.365523\n",
            "[10000]\tvalid_set's rmse: 0.36551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.3655\t = Validation score   (-root_mean_squared_error)\n",
            "\t46.12s\t = Training   runtime\n",
            "\t1.53s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.353126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.352\t = Validation score   (-root_mean_squared_error)\n",
            "\t10.33s\t = Training   runtime\n",
            "\t0.24s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-0.3941\t = Validation score   (-root_mean_squared_error)\n",
            "\t97.03s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.3511\t = Validation score   (-root_mean_squared_error)\n",
            "\t231.89s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-0.4309\t = Validation score   (-root_mean_squared_error)\n",
            "\t17.13s\t = Training   runtime\n",
            "\t0.27s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-0.2992\t = Validation score   (-root_mean_squared_error)\n",
            "\t13.84s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.3977\t = Validation score   (-root_mean_squared_error)\n",
            "\t23.64s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-0.3927\t = Validation score   (-root_mean_squared_error)\n",
            "\t22.62s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t-0.3364\t = Validation score   (-root_mean_squared_error)\n",
            "\t10.49s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t-0.2621\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.59s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 481.83s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230311_154304/Predictor_Sim 3 Bottom Bracket Y Disp. Magnitude/\")\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230311_154304/Predictor_Sim 3 Bottom Bracket X Rot. Magnitude/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.9.16\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    11138\n",
            "Train Data Columns: 45\n",
            "Label Column: Sim 3 Bottom Bracket X Rot. Magnitude\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (51.30419683230974, -1.0187609518276375, -0.0007, 1.05076)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11046.82 MB\n",
            "\tTrain Data (Original)  Memory Usage: 4.01 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting TabularPredictor for label: Sim 3 Bottom Bracket X Rot. Magnitude ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 45 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 40 | ['CS Length', 'BB Drop', 'Stack', 'SS E', 'ST Angle', ...]\n",
            "\t\t('int', ['bool']) :  5 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include']\n",
            "\t0.2s = Fit runtime\n",
            "\t45 features in original data used to generate 45 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 3.62 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.23s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 10024, Val Rows: 1114\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-0.6443\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.3s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-0.6202\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.23s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t-0.3888\t = Validation score   (-root_mean_squared_error)\n",
            "\t6.98s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.419921\n",
            "[2000]\tvalid_set's rmse: 0.404316\n",
            "[3000]\tvalid_set's rmse: 0.399848\n",
            "[4000]\tvalid_set's rmse: 0.388487\n",
            "[5000]\tvalid_set's rmse: 0.382981\n",
            "[6000]\tvalid_set's rmse: 0.381903\n",
            "[7000]\tvalid_set's rmse: 0.381617\n",
            "[8000]\tvalid_set's rmse: 0.38153\n",
            "[9000]\tvalid_set's rmse: 0.381497\n",
            "[10000]\tvalid_set's rmse: 0.381501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.3815\t = Validation score   (-root_mean_squared_error)\n",
            "\t68.74s\t = Training   runtime\n",
            "\t1.64s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-0.4025\t = Validation score   (-root_mean_squared_error)\n",
            "\t94.97s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.3408\t = Validation score   (-root_mean_squared_error)\n",
            "\t240.27s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-0.4167\t = Validation score   (-root_mean_squared_error)\n",
            "\t19.23s\t = Training   runtime\n",
            "\t0.25s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-0.3552\t = Validation score   (-root_mean_squared_error)\n",
            "\t14.17s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.3811\t = Validation score   (-root_mean_squared_error)\n",
            "\t10.25s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-0.3852\t = Validation score   (-root_mean_squared_error)\n",
            "\t32.25s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t-0.3251\t = Validation score   (-root_mean_squared_error)\n",
            "\t15.46s\t = Training   runtime\n",
            "\t0.13s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t-0.2866\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.58s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 510.71s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230311_154304/Predictor_Sim 3 Bottom Bracket X Rot. Magnitude/\")\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230311_154304/Predictor_Sim 1 Safety Factor (Inverted)/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.9.16\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    11138\n",
            "Train Data Columns: 46\n",
            "Label Column: Sim 1 Safety Factor (Inverted)\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (89.63932055031486, -0.3939172743614557, 0.00474, 1.10523)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11102.16 MB\n",
            "\tTrain Data (Original)  Memory Usage: 4.1 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting TabularPredictor for label: Sim 1 Safety Factor (Inverted) ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 46 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 41 | ['CS Length', 'BB Drop', 'Stack', 'SS E', 'ST Angle', ...]\n",
            "\t\t('int', ['bool']) :  5 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include']\n",
            "\t0.2s = Fit runtime\n",
            "\t46 features in original data used to generate 46 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 3.71 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.26s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 10024, Val Rows: 1114\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-2.6015\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-2.6011\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.05s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 2.56812\n",
            "[2000]\tvalid_set's rmse: 2.56246\n",
            "[3000]\tvalid_set's rmse: 2.56176\n",
            "[4000]\tvalid_set's rmse: 2.56153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-2.5613\t = Validation score   (-root_mean_squared_error)\n",
            "\t22.18s\t = Training   runtime\n",
            "\t0.6s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-2.5875\t = Validation score   (-root_mean_squared_error)\n",
            "\t7.91s\t = Training   runtime\n",
            "\t0.13s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-2.6204\t = Validation score   (-root_mean_squared_error)\n",
            "\t142.09s\t = Training   runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-2.5992\t = Validation score   (-root_mean_squared_error)\n",
            "\t43.46s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-2.5901\t = Validation score   (-root_mean_squared_error)\n",
            "\t20.57s\t = Training   runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-2.2301\t = Validation score   (-root_mean_squared_error)\n",
            "\t12.04s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-2.5968\t = Validation score   (-root_mean_squared_error)\n",
            "\t11.25s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-2.5861\t = Validation score   (-root_mean_squared_error)\n",
            "\t37.3s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t-2.5911\t = Validation score   (-root_mean_squared_error)\n",
            "\t8.26s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t-2.2301\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.63s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 310.62s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230311_154304/Predictor_Sim 1 Safety Factor (Inverted)/\")\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230311_154304/Predictor_Sim 3 Safety Factor (Inverted)/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.9.16\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    11138\n",
            "Train Data Columns: 47\n",
            "Label Column: Sim 3 Safety Factor (Inverted)\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (87.8663152959725, -0.37389303855875977, 0.00536, 1.11318)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11102.67 MB\n",
            "\tTrain Data (Original)  Memory Usage: 4.19 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting TabularPredictor for label: Sim 3 Safety Factor (Inverted) ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 47 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 42 | ['CS Length', 'BB Drop', 'Stack', 'SS E', 'ST Angle', ...]\n",
            "\t\t('int', ['bool']) :  5 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include']\n",
            "\t0.2s = Fit runtime\n",
            "\t47 features in original data used to generate 47 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 3.8 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.24s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 10024, Val Rows: 1114\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-2.4155\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.19s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-2.4099\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.13s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 2.60588\n",
            "[2000]\tvalid_set's rmse: 2.59912\n",
            "[3000]\tvalid_set's rmse: 2.59795\n",
            "[4000]\tvalid_set's rmse: 2.59745\n",
            "[5000]\tvalid_set's rmse: 2.59739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-2.5973\t = Validation score   (-root_mean_squared_error)\n",
            "\t30.18s\t = Training   runtime\n",
            "\t0.65s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-2.5013\t = Validation score   (-root_mean_squared_error)\n",
            "\t4.74s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-2.4389\t = Validation score   (-root_mean_squared_error)\n",
            "\t123.61s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-2.5392\t = Validation score   (-root_mean_squared_error)\n",
            "\t14.41s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-2.3529\t = Validation score   (-root_mean_squared_error)\n",
            "\t26.37s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 3: early stopping\n",
            "\t-0.6898\t = Validation score   (-root_mean_squared_error)\n",
            "\t8.91s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-2.4681\t = Validation score   (-root_mean_squared_error)\n",
            "\t10.76s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-2.4117\t = Validation score   (-root_mean_squared_error)\n",
            "\t17.2s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t-2.5093\t = Validation score   (-root_mean_squared_error)\n",
            "\t12.23s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t-0.6332\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.39s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 253.21s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230311_154304/Predictor_Sim 3 Safety Factor (Inverted)/\")\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230311_154304/Predictor_Model Mass Magnitude/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.9.16\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    11138\n",
            "Train Data Columns: 48\n",
            "Label Column: Model Mass Magnitude\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (6.589862539032262, -1.6897076835673173, 0.0003, 1.0019)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11127.4 MB\n",
            "\tTrain Data (Original)  Memory Usage: 4.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting TabularPredictor for label: Model Mass Magnitude ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 48 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 43 | ['CS Length', 'BB Drop', 'Stack', 'SS E', 'ST Angle', ...]\n",
            "\t\t('int', ['bool']) :  5 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include']\n",
            "\t0.2s = Fit runtime\n",
            "\t48 features in original data used to generate 48 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 3.89 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.22s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 10024, Val Rows: 1114\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-0.4451\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-0.3898\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.130262\n",
            "[2000]\tvalid_set's rmse: 0.121705\n",
            "[3000]\tvalid_set's rmse: 0.119761\n",
            "[4000]\tvalid_set's rmse: 0.118868\n",
            "[5000]\tvalid_set's rmse: 0.118418\n",
            "[6000]\tvalid_set's rmse: 0.118199\n",
            "[7000]\tvalid_set's rmse: 0.1181\n",
            "[8000]\tvalid_set's rmse: 0.118005\n",
            "[9000]\tvalid_set's rmse: 0.117959\n",
            "[10000]\tvalid_set's rmse: 0.117932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.1179\t = Validation score   (-root_mean_squared_error)\n",
            "\t50.92s\t = Training   runtime\n",
            "\t1.44s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.139065\n",
            "[2000]\tvalid_set's rmse: 0.137905\n",
            "[3000]\tvalid_set's rmse: 0.137671\n",
            "[4000]\tvalid_set's rmse: 0.137545\n",
            "[5000]\tvalid_set's rmse: 0.137443\n",
            "[6000]\tvalid_set's rmse: 0.137409\n",
            "[7000]\tvalid_set's rmse: 0.137388\n",
            "[8000]\tvalid_set's rmse: 0.137382\n",
            "[9000]\tvalid_set's rmse: 0.137379\n",
            "[10000]\tvalid_set's rmse: 0.137375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.1374\t = Validation score   (-root_mean_squared_error)\n",
            "\t70.46s\t = Training   runtime\n",
            "\t1.45s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-0.2172\t = Validation score   (-root_mean_squared_error)\n",
            "\t90.23s\t = Training   runtime\n",
            "\t0.28s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.1095\t = Validation score   (-root_mean_squared_error)\n",
            "\t242.05s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-0.2049\t = Validation score   (-root_mean_squared_error)\n",
            "\t20.22s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-0.1252\t = Validation score   (-root_mean_squared_error)\n",
            "\t13.05s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.1423\t = Validation score   (-root_mean_squared_error)\n",
            "\t32.65s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-0.1322\t = Validation score   (-root_mean_squared_error)\n",
            "\t43.27s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.151324\n",
            "[2000]\tvalid_set's rmse: 0.15108\n",
            "[3000]\tvalid_set's rmse: 0.151059\n",
            "[4000]\tvalid_set's rmse: 0.151057\n",
            "[5000]\tvalid_set's rmse: 0.151056\n",
            "[6000]\tvalid_set's rmse: 0.151056\n",
            "[7000]\tvalid_set's rmse: 0.151056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.1511\t = Validation score   (-root_mean_squared_error)\n",
            "\t185.56s\t = Training   runtime\n",
            "\t1.28s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t-0.1011\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.4s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 764.32s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230311_154304/Predictor_Model Mass Magnitude/\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('AutogluonModels/ag-20230311_154304/')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_predictor = MultilabelPredictor.load(\"AutogluonModels/ag-20230311_154304/\")\n",
        "predictions = my_predictor.predict(x_test)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "\n",
        "r2, mse, mae"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdQjKO1ZhGuz",
        "outputId": "bd959330-8253-48d9-e02d-53b914fd08e3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.63394409450457, 0.21365510395757425, 0.12860334010343127)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive(\"trained-model-8pm\", \"zip\", \"/content/AutogluonModels\")\n"
      ],
      "metadata": {
        "id": "yHX6e5pJ-KdH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b80de1a0-4579-42ee-f769-09362675c0bf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/trained-model-8pm.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4-uVflVSDr1E"
      }
    }
  ]
}